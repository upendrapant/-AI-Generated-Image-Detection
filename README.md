# Backend ML Project

[![Python](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://www.python.org/)  
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

---

A robust backend machine learning system for training, evaluating, and serving image classification models, with a modern API for AI-generated image detection.

---

## üöÄ Key Features

- **Vision Transformer (ViT) Model** for AI-generated vs. real image classification
- **Advanced Training Pipeline** with improved data augmentation and monitoring
- **REST API** for batch image analysis (FastAPI-based)
- **Easy Inference** via scripts or API
- **TensorBoard** logging for training visualization
- **Modular, extensible codebase**

---

## üìÅ Project Structure

```
backend/
‚îú‚îÄ‚îÄ config.py              # Configuration settings
‚îú‚îÄ‚îÄ dataset.py             # Dataset utilities
‚îú‚îÄ‚îÄ env/                   # Python virtual environment (not tracked)
‚îú‚îÄ‚îÄ logs/                  # Training logs and visualizations
‚îÇ   ‚îî‚îÄ‚îÄ improved_vit/      # TensorBoard event files
‚îú‚îÄ‚îÄ main.py                # Main entry point
‚îú‚îÄ‚îÄ models/                # Saved model artifacts (.pth files)
‚îú‚îÄ‚îÄ quick_start.py         # Quick start script
‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îú‚îÄ‚îÄ run_improved_training.py # Improved training script
‚îú‚îÄ‚îÄ server/                # API server (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ api.py             # API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ inference.py       # Inference logic
‚îÇ   ‚îú‚îÄ‚îÄ model/             # Model files for serving
‚îÇ   ‚îú‚îÄ‚îÄ package.json       # Node.js dependencies (if any)
‚îÇ   ‚îî‚îÄ‚îÄ node_modules/      # Node.js packages (not tracked)
‚îú‚îÄ‚îÄ train.py               # Training script
‚îú‚îÄ‚îÄ train_improved.py      # Improved training script
‚îú‚îÄ‚îÄ utils.py               # Utility functions
‚îú‚îÄ‚îÄ vision_transformer.py  # Vision Transformer model
‚îî‚îÄ‚îÄ IMPROVEMENTS.md        # Project improvement notes
```

---

## üõ†Ô∏è Technologies Used

- **Python 3.10+**
- **PyTorch** (Deep Learning)
- **FastAPI** (REST API)
- **Albumentations** (Image Augmentation)
- **TorchVision** (Image Processing)
- **TensorBoard** (Visualization)
- **Uvicorn** (ASGI Server)
- **Flask** (optional, legacy support)

---

## üß© Project Workflow

```mermaid
graph TD;
    A[Prepare Dataset] --> B[Train Model];
    B --> C[Evaluate & Log Metrics];
    C --> D[Save Best Model];
    D --> E[Run Inference Script];
    D --> F[Serve via API];
    F --> G[Client/API User]
```

---

## ‚ö° Quick Start

1. **Clone the repository:**
   ```sh
   git clone <repo-url>
   cd backend
   ```
2. **Create and activate a virtual environment:**
   ```sh
   python -m venv env
   # On Windows:
   .\env\Scripts\activate
   # On Unix/Mac:
   source env/bin/activate
   ```
3. **Install dependencies:**
   ```sh
   pip install -r requirements.txt
   ```

---

## üèãÔ∏è‚Äç‚ôÇÔ∏è Training & Inference

- **Train the model:**
  ```sh
  python train.py
  # or for improved training
  python train_improved.py
  ```
- **Run inference on an image:**
  ```sh
  python inference.py --model_path models/best_model_improved.pth --image_path your_image.jpg
  ```
- **Monitor training:**
  ```sh
  tensorboard --logdir logs/improved_vit
  ```

---

## üåê Server API

The API server (in `server/`) uses **FastAPI** to provide a REST endpoint for batch image analysis.

### Start the API Server

```sh
cd server
uvicorn api:app --reload
```

### Main Endpoint

#### `POST /analyze`
- **Description:** Analyze one or more images to determine if they are AI-generated or real.
- **Request:**
  - `multipart/form-data` with one or more files (field name: `files`)
- **Response:**
  - JSON array, one object per image:
    - `filename`: Name of the image file
    - `prediction`: "AI-Generated" or "Real"
    - `confidence`: Model confidence (0-1)
    - `ai_generated_probability`: Probability image is AI-generated
    - `real_probability`: Probability image is real

**Example using `curl`:**
```sh
curl -F "files=@image1.jpg" -F "files=@image2.png" http://127.0.0.1:8000/analyze
```
**Sample Response:**
```json
[
  {
    "filename": "image1.jpg",
    "prediction": "AI-Generated",
    "confidence": 0.98,
    "ai_generated_probability": 0.98,
    "real_probability": 0.02
  },
  {
    "filename": "image2.png",
    "prediction": "Real",
    "confidence": 0.95,
    "ai_generated_probability": 0.05,
    "real_probability": 0.95
  }
]
```

---

## üìà Improvements & Research

See [IMPROVEMENTS.md](IMPROVEMENTS.md) for a detailed list of model and pipeline improvements, including:
- Higher image resolution
- Enhanced ViT architecture
- Advanced data augmentation
- Improved training techniques
- Better monitoring and logging

---

## ü§ù Contributing

Contributions, issues, and feature requests are welcome! Please open an issue or submit a pull request.

---

## üìÑ License

This project is licensed under the MIT License.

---

## ‚ùì FAQ / Troubleshooting

- **Training is slow:**
  - Try reducing batch size or number of epochs in `config.py`.
  - Ensure you are using a GPU if available.
- **Accuracy is not improving:**
  - Check your dataset quality and balance.
  - Try increasing training epochs or adjusting learning rate.
- **API server not starting?**
  - Ensure all dependencies are installed and the model file exists in `server/model/`.
- **Where are logs and models?**
  - See the `logs/` and `models/` directories. These are not tracked by git.

---

For more details, see the code and documentation in each module, or open an issue for help! 